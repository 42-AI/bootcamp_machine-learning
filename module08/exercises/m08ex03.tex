\chapter{Exercise 03}
\extitle{Vectorized Logistic Loss Function}
\input{exercises/en.ex03_interlude.tex}
\newpage
\turnindir{ex03}
\exnumber{03}
\exfiles{vec\_log\_loss.py}
\exforbidden{any function that calculates the derivatives for you}
\makeheaderfilesforbidden

% ================================= %
\section*{Objective}
% --------------------------------- %
Understanding and manipulation of loss function in the context of logistic regression.\\
\\
You must implement the following formula as a function:  

$$
J( \theta) = -\cfrac{1} {m} \lbrack y \cdot \log(\hat{y}) + (\vec{1} - y) \cdot \log(\vec{1} - \hat{y})\rbrack
$$
\\
Where:
\begin{itemize}
  \item $\hat{y}$ is a vector of dimension $m$, the vector of predicted values
  \item $y$ is a vector of dimension $m$, the vector of expected values
  \item $\vec{1}$ is a vector of dimension $m$, a vector full of 1's
\end{itemize}


% ================================= %
\section*{Instructions}
% --------------------------------- %
In the \texttt{vec\_log\_loss.py} file, write the following function as per the instructions below:\\
\\
\begin{minted}[bgcolor=darcula-back,formatcom=\color{lightgrey},fontsize=\scriptsize]{python}
def vec_log_loss_(y, y_hat, eps=1e-15):
    """
    Computes the logistic loss value.
    Args:
        y: has to be an numpy.ndarray, a vector of shape m * 1.
        y_hat: has to be an numpy.ndarray, a vector of shape m * 1.
        eps: epsilon (default=1e-15)
    Returns:
        The logistic loss value as a float.
        None on any error.
    Raises:
        This function should not raise any Exception.
    """
\end{minted}

\hint{
  The purpose of epsilon (eps) is to avoid $log(0)$ errors, it is a very small residual value we add to y.
}

% ================================= %
\section*{Examples}
% --------------------------------- %
\begin{minted}[bgcolor=darcula-back,formatcom=\color{lightgrey},fontsize=\scriptsize]{python}
# Example 1:
y1 = np.array([1]).reshape((-1, 1))
x1 = np.array([4]).reshape((-1, 1))
theta1 = np.array([[2], [0.5]])
y_hat1 = logistic_predict_(x1, theta1)
vec_log_loss_(y1, y_hat1)
# Output:
0.018149927917808714

# Example 2:
y2 = np.array([[1], [0], [1], [0], [1]])
x2 = np.array([[4], [7.16], [3.2], [9.37], [0.56]])
theta2 = np.array([[2], [0.5]])
y_hat2 = logistic_predict_(x2, theta2)
vec_log_loss_(y2, y_hat2)
# Output:
2.4825011602472347

# Example 3:
y3 = np.array([[0], [1], [1]])
x3 = np.array([[0, 2, 3, 4], [2, 4, 5, 5], [1, 3, 2, 7]])
theta3 = np.array([[-2.4], [-1.5], [0.3], [-1.4], [0.7]])
y_hat3 = logistic_predict_(x3, theta3)
vec_log_loss_(y3, y_hat3)
# Output:
2.993853310859968
\end{minted}