# Module08 - Logistic Regression

Today, you will discover your first classification algorithm: logistic regression. You will learn its cost function, gradient descent and some metrics to evaluate its performance.

## Notions of the module

Logistic hypothesis, logistic gradient descent, logistic regression, multiclass classification. 
Accuracy, precision, recall, F1-score, confusion matrix.

## Useful Resources  
  
We strongly advise that you use the following resource:
[Machine Learning MOOC - Stanford](https://www.coursera.org/learn/machine-learning/home/week/3)  
Here are the sections of the MOOC that are relevant for today's exercises: 

### Week 3: 

**Classification and representation:**
* Classification (Video + Reading)
* Hypothesis Representation (Video + Reading)
* Decision Boundary (Video + Reading)

**Logistic Regression Model:**
* Cost Function (Video + Reading)
* Simplified Cost Function and Gradient Descent (Video + Reading)
 
**Multiclass Classification:**
* Mutliclass Classification: One-vs-all (Video + Reading)

* Review (Reading + Quiz)

## General rules

* The Python version to use is 3.7, you can check with the following command: `python -V`
* The norm: during this bootcamp you will follow the [Pep8 standards](https://www.python.org/dev/peps/pep-0008/)
* The function `eval` is never allowed.
* The exercises are ordered from the easiest to the hardest.
* Your exercises are going to be evaluated by someone else, so make sure that your variable names and function names are appropriate and civil. 
* Your manual is the internet.
* You can also ask questions in the `#bootcamps` channel in [42AI's Slack workspace](https://42-ai.slack.com).
* If you find any issues or mistakes in this document, please create an issue on our [dedicated Github repository](https://github.com/42-AI/bootcamp_machine-learning/issues).

## Helper

Ensure that you have the right Python version.

```
> which python
/goinfre/miniconda/bin/python
> python -V
Python 3.7.*
> which pip
/goinfre/miniconda/bin/pip
```

### Exercise 00 - Multivariate Linear Regression with Class

### Exercise 01 - DataSplitter

### Exercise 02 - Ai Key Notions

### Interlude -  Classification: The Art of Labelling Things

### Interlude - Predict I: Introducing the Sigmoid Function

### Exercise 03 - Sigmoid

### Interlude - Predict II: Hypothesis

### Exercise 04 - Logistic Hypothesis

### Interlude - Evaluate

### Exercise 05 - Logistic Loss Function

### Interlude - Linear Algebra Strikes again!

### Exercise 06 - Vectorized Logistic Loss Function

### Interlude - Improve

### Exercise 07 - Logistic Gradient

### Interlude - Vectorized Logistic Gradient 

### Exercise 08 - Vectorized Logistic Gradient

### Exercise 09 - Logistic Regression

### Exercise 10 - Practicing Logistic Regression

### Interlude - More Evaluation Metrics!

### Exercise 11 - Other metrics

### Exercise 12 - Confusion Matrix
