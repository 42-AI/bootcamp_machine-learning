# Bootcamp ML

# Day03 - Regularization and Feature engineering

Congratulations! You made it to the day03 of the machine learning bootcamp! Today you will see the L2 regularization and how to implement it in both linear and logistic regression. Then we will see a few ways to process your data in order to improve significantly the performance of your models. 


## Notions of the day

* Regularization 
* Regularized linear regression
* Regularized logistic regression
* Z-score standardization
* min-max standardization
* Polynomial features
* Interaction terms 


## Useful Ressources  
  
[Machine Learning MOOC - Stanford](https://www.coursera.org/learn/machine-learning/home/week/3)  

### Week 3: 

**Regularization:**

* The Problem of Overfitting (Video + Reading)
* Cost Function (Video + Reading)
* Regularized Linear Regression (Video + Reading)
* Regularized Logistic Regression (Video + Reading)
* Review (Reading + Quiz)
 
 
## General rules

* The version of Python to use is 3.7, you can check the version of Python with the following command: `python -V`
* The norm: during this bootcamp you will follow the Pep8 standards https://www.python.org/dev/peps/pep-0008/
* The function eval is never allowed.
* The exercises are ordered from the easiest to the hardest.
* Your exercises are going to be evaluated by someone else, so make sure that your variable names and function names are appropriate and civil. 
* Your manual is the internet.
* You can also ask questions in the dedicated channel in the 42 AI Slack: 42-ai.slack.com.
* If you find any issue or mistakes in the subject please create an issue on our dedicated repository on Github:  https://github.com/42-AI/bootcamp_machine-learning/issues.

## Helper 

Ensure that you have the right Python version.

```
> which python
/goinfre/miniconda/bin/python
> python -V
Python 3.7.*
> which pip
/goinfre/miniconda/bin/pip
```

## Mathematical delights (continued)

### Exercise 00 - Regularization - iterative version

### Exercise 01 - Regularization - vectorized version

### Exercise 02 - Regularized Mean Squared Error

### Exercise 03 - Regularized Linear Gradient - iterative version

### Exercise 04 - Regularized Linear Gradient - vectorized version

### Exercise 05 - Regularized Logistic Loss Function

### Exercise 06 - Regularized Logistic Gradient - iterative version

### Exercise 07 - Regularized Logistic Gradient - vectorized version


## Algorithm

### Exercise 08 - Ridge Regression Method

### Exercise 09 - Regularized Logistic regression


## Feature Engineering

### Exercise 10 - Z-score standardization

### Exercise 11 - Min-max standardization

### Exercise 12 - Polynomial Features
