# Bootcamp ML
​
# Day03 - Regularization and Feature engineering
​
Congratulations! You made it to the day03 of the machine learning bootcamp! Today you will see the L2 regularization and how to implement it in both linear and logistic regression. Then we will see a few ways to process your data in order to improve significantly the performance of your models. 
​
​
## Notions of the day
​
* Regularization 
* Regularized linear regression
* Regularized logistic regression
* z-score standardization
* min-max standardization
* Polynomial features
* Interaction terms 


## Useful Ressources  
  
Machine Learning MOOC - Stanford:  
https://www.coursera.org/learn/machine-learning/home/week/3

### Week 3: 

**Regularization:**

* The Problem of Overfitting (Video + Reading)
* Cost Function (Video + Reading)
* Regularized Linear Regression (Video + Reading)
* Regularized Logistic Regression (Video + Reading)
* Review (Reading + Quiz)
 
 
## General rules
​
* The version of Python to use is 3.7, you can check the version of Python with the following command: `python -V`
* The norm: during this bootcamp you will follow the Pep8 standards https://www.python.org/dev/peps/pep-0008/
* The function eval is never allowed.
* The exercises are ordered from the easiest to the hardest.
* Your exercises are going to be evaluated by someone else, so make sure that your variable names and function names are appropriate and civil. 
* Your manual is the internet.
* You can also ask questions in the dedicated channel in the 42 AI Slack: 42-ai.slack.com.
* If you find any issue or mistakes in the subject please create an issue on our dedicated repository on Github:  https://github.com/42-AI/bootcamp_machine-learning/issues.
​
## Helper 
​
Ensure that you have the right Python version.
​
```
> which python
/goinfre/miniconda/bin/python
> python -V
Python 3.7.*
> which pip
/goinfre/miniconda/bin/pip
```
​
## Mathematical delights (continued)
​
### Exercice 00 - Ridge - iterative version 
​
### Exercice 01 - Ridge - vectorized version
​
### Exercice 02 - Regularized MSE
​
### Exercice 03 - Regularized Linear Gradient - iterative version
​
### Exercice 04 - Regularized Linear Gradient - vectorized version
​
### Exercice 05 - Regularized Logistic Loss
​
### Exercice 06 - Regularized Logistic Gradient - iterative version
​
### Exercice 07 - Regularized Logistic Gradient - vectorized version
​
​
## Algorithm
​
### Exercice 08 - Ridge regression
​
### Exercice 09 - Regularized Logistic regression
​
​
## Feature Engineering
​
### Exercice 10 - Z-score standardization
​
### Exercice 11 - Min-max standardization
​
### Exercice 12 - Polynomial features + interaction terms
