# Exercise 08 - Ridge Regression Method

|                         |                    |
| -----------------------:| ------------------ |
|   Turn-in directory :   |  ex08              |
|   Files to turn in :    |  ridge_reg.py      |
|   Forbidden functions : |  \*.sum()          |
|   Forbidden classes :   | sklearn.linear_model.Ridge |
|   Authorized classes :  | sklearn.model_selection.LeaveOneOut |
|                         | sklearn.model_selection.KFold |
|   Remarks :             |  n/a               |
|   Helpful links :       |  [Machine Learning Mooc / Week 3 - Regularized Linear Regression](https://www.coursera.org/learn/machine-learning/lecture/QrMXd/regularized-linear-regression) |

## Objectives:

* Understand the limit of a hypothesis.
* Understand of the notions of biais and variance.
* Implementation of a class named **MyRidge** similar to the class of the same name in **sklearn.linear_model**.
* Perform linear regression splitting the dataset in 3 sets: train, cross-validation and test.


## Part One - Back to the _Future_ Past

_If I had an hour to solve a problem I would spend 55 minutes thinking about the problem and 5 minutes thinking about the solutions. (Albert Einstein)_  
Thus, be smart ! This should remind you something you already coded.

### Instructions:
For this part, your class **MyRidge**  will have several methods:
* `__init__` , special method, identical to the one of the class **MyLinearRegression** (Day01),
* `predict_` , which predict output using a linear model,
* `fit_` , which fit Ridge regression model
* a few metric methods: `mse_` ,  `rmse_` , `r2score_` .

Except for `.fit_` the methods are identicals to the ones of your class **MyLinearRegression**.
_You should consider inheritance_

The difference between the method `.fit_` of **MyRidge** class and the method `.fit_` of **MyLinearRegression** is the use of a regularization term.
The cost function:

$$
J(\mathbf{\theta}) = \frac{1}{2m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^2+\frac{\lambda}{2m}\sum_{j=1}^{n}\theta_j^2
$$

Where:
* m is the number of training examples (or the length of the dataset),
* n is the number of features,
* $x^{(i)}$ is the input (all features values) of the ith training example,
* $y^{(i)}$ is is the output of the ith training example,
* $\lambda$ is regularization parameter (or Tikhonov parameter).
Beware of in the second summation term, the index j start at 1 and not 0 ($\theta_0$ is not penalized).

Code your class **MyRidge** as per the instructions below:
```python
class MyRidge(ParentClass):
	fit_(self, X, Y, alpha = 0.005, n_cycle = 1000, lambda = 1):
		"""
		Fit the linear model by performing Ridge regression (Tikhonov regularization).
		Args:
		  lambda: has to be a float. max_iter: has to be integer.
		  tol: has to be float.
		Returns:
		  Nothing.
		Raises:
		  This method should not raise any Exception.
		"""
```
Regularization parameter must be a positive float.


Try your method with the dataset named **dataset.csv**.
The dataset is made of 3 columns: 2 features and the output (x1, x2 and y).
You have representations of the dataset in the following figure:

<img src="day03/assets/figure1_3Dplot_dataset.png" />

The best hypothesis for your data has the following form:

$$
h(x_1,x_2) = \theta_0 + \theta_1.x_1 + \theta_2.x_1^3 + \theta_3.x_2 + \theta_4.x_2^2
$$

Plot a graph with 3 curves:
* The output with respect to one feature,
* The model you get when you fit the data with the method **.fit()** of your class **MyLinearRegression**,
* The model you get when you fit the data with the method **.fit\_()** of your class **MyRidge**.


## Bonus Part - Do linear regression like a pro ... Well almost

Well, now it is time to tell you that performing linear regression with the whole dataset is really bad!
Hopefully you will learn how to do it correctly in this part.

### Instructions:
Redo what you did in Part One, using the good practice:

Plot a graph with 3 curves:
* The output with respect to one feature,
* The model you get when you fit the data with the method **.fit()** of your class **MyLinearRegression**,
* The model you get when you fit the data with the method **.fit\_()** of your class **MyRidge**.

### Good practice:
In **day01** you probably fit your data with the entire dataset.
This is not a good practice!
You should at least divide the dataset in 2 sets : a training set and a test set.
A even better practice is to divide your dataset in 3 sets: training set, cross-validation set and a test set. 
Several techniques exist to do a good training/cross-validation process: the _LeaveOneOut_, _KFold_ and so on (which you can find in sklearn: **sklearn.model_selection.LeaveOneOut** or **sklearn.model_selection.KFold**).
See documentation on internet about it to get more information.

For this part, we will simplify the process:
* You will split your data set into 3 sets: training set, cross-validation set and testing set.
* The training set will be represent 60 % of the dataset and the cross-validation set will correspond to 20 % of the dataset.
* Perform few training with different values of $\lambda$ (choose the values but stay coherent!).
* Choose the best set of $\theta$ coefficients based on the error results (RMSE and R2 score for example) of your cross-validation.
* And verify if your model is a good generalization by calculating the error results  on the testing set.

Answer to the following question (with quantitative arguments):
* Which model is better?


## Questions:

* What is the biais and the variance?
* A variation of the regularization parameter leads to an evolution of the biais and the variance of a model. How the variance and the biais evolve with the regularization parameter?
