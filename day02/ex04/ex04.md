# Exercise 04 - Vectorized Logistic Gradient

|                         |                         |
| -----------------------:| ----------------------- |
|   Turn-in directory :   |  ex04                   |
|   Files to turn in :    |  vec_log_gradient.py    |
|   Forbidden functions : |  None                   |
|   Remarks :             |  n/a                    |

## Objectives:

Now that you understood how we can calculate the gradient, you will see how to do it with vectorized operations.
The goal of this exercise is to produce the same result as in ex02 but this time you will use NumPy ndarrays.
You should only need one line of code to do this (`return ______`).


## Instructions:

In the vec_log_gradient.py file create the following function as per the instructions below: 
```python
def vec_log_gradient_(x, y_true, y_pred):
 """
    Compute the gradient.
    Args:
        x: a 1d or 2d numpy ndarray for the samples
        y_true: a scalar or a numpy ndarray for the correct labels
        y_pred: a scalar or a numpy ndarray for the predicted labels
    Returns: 
        The gradient as a scalar or a numpy ndarray of the width of x.
        None on any error.
    Raises:
        This function should not raise any Exception.
    """
```
  
* x length (x.shape[0] if it is a 2d ndarray) should match y_true and y_pred length, i.e. we should have the same number of observations.
* x width (x.shape[1] if it is a 2d ndarray) will be the number of variables of your model (add 1 if you choose to add an intercept value) and it should match theta's length, but this is for later when we will update theta in our gradient descent algorithm.


## Examples:
```python
import numpy as np
from sigmoid import sigmoid_
from vec_log_gradient import vec_log_gradient_

# Test n.1
x = np.array([1, 4.2])  # x[0] represent the intercept
y_true = 1
theta = np.array([0.5, -0.5])
y_pred = sigmoid_(np.dot(x, theta))
print(vec_log_gradient_(x, y_pred, y_true))
# [0.83201839 3.49447722]

# Test n.2
x = np.array([1, -0.5, 2.3, -1.5, 3.2]) # x[0] represent the intercept
y_true = 0
theta = np.array([0.5, -0.5, 1.2, -1.2, 2.3])
y_pred = sigmoid_(np.dot(x, theta))
print(vec_log_gradient_(x, y_true, y_pred))
# [ 0.99999686 -0.49999843  2.29999277 -1.49999528  3.19998994]

# Test n.3
x_new = np.arange(2, 14).reshape((3, 4))
x_new = np.insert(x_new, 0, 1, axis=1)
# first column of x_new are now intercept values initialized to 1
y_true = np.array([1, 0, 1])
theta = np.array([0.5, -0.5, 1.2, -1.2, 2.3])
y_pred = sigmoid_(np.dot(x_new, theta))
print(vec_log_gradient_(x_new, y_true, y_pred))
# [0.99994451 5.99988885 6.99983336 7.99977787 8.99972238]
```
