# Day02 - Multivariate Linear Regression

Building on what you did on the previous days you will extend the linear regression to handle more than one features. 
Then you will see how to build polynomial models and how to detect overfitting.

## Notions of the Day
Multivariate linear hypothesis, multivariate linear gradient descent, polynomial models. 
Training and test sets, overfitting.

## Useful Ressources  
  
We strongly advise you to use the following resource:
[Machine Learning MOOC - Stanford](https://www.coursera.org/learn/machine-learning/home/week/2)  
Here are the sections of the MOOC that are relevant for today's exercises: 

### Week 2: 

**Multivariate Linear Regression:**
* Multiple Features (Video + Reading)
* Gradient Descent for Multiple Variables (Video + Reading)
* Gradient Descent in Practice I- Feature Scaling (Video + Reading)
* Gradient Descent in Practice II- Learning Rate (Video + Reading)
* Features and Polynomial Regression (Video + Reading)
* Review (Reading + Quiz)

## General rules

* The Python version to use is 3.7, you can check with the following command: `python -V`
* The norm: during this bootcamp you will follow the [Pep8 standards](https://www.python.org/dev/peps/pep-0008/)
* The function `eval` is never allowed.
* The exercises are ordered from the easiest to the hardest.
* Your exercises are going to be evaluated by someone else, so make sure that your variable names and function names are appropriate and civil. 
* Your manual is the internet.
* You can also ask questions in the `#bootcamps` channel in [42AI's Slack workspace](https://42-ai.slack.com).
* If you find any issues or mistakes in this document, please create an issue on our [dedicated Github repository](https://github.com/42-AI/bootcamp_machine-learning/issues).

## Helper

Ensure that you have the right Python version.

```
> which python
/goinfre/miniconda/bin/python
> python -V
Python 3.7.*
> which pip
/goinfre/miniconda/bin/pip
```


### Exercise 00 - Linear Regression with Class

### Exercise 01 - Ai Key Notions

### Interlude -  To the Multivariate Universe and Beyond!

### Exercise 02 - Multivariate Hypothesis - Iterative Version

### Interlude - Even More Linear Algebra Tricks!

### Exercise 03 - Multivariate hypothesis - vectorized version

### Interlude - Evaluate

### Exercise 04 - Vectorized Cost Function

### Interlude - Improve with the Gradient

### Exercise 05 - Multivariate Linear Gradient

### Interlude - Gradient Descent

### Exercise 06 - Multivariate Gradient Descent

### Exercise 07 - Multivariate Linear Regression with Class

### Exercise 08 - Practicing Multivariate Linear Regression

### Exercise 9 - Question Time!

### Interlude - Introducing Polynomial Models

### Exercise 10 - Polynomial models

### Exercise 11 - Let's Train Polynomial Models! 

### Interlude - Plotting Curves With Matplotlib

### Exercise 12 - Let's PLOT some Polynomial Models! 

### Interlude - Lost in Overfitting

### Exercise 13 - DataSpliter

### Exercise 14 - Machine Learning for Grown-ups: Training and Test Sets

### Exercise 15 - Question Time!
