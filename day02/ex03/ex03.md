# Exercise 03 - Vectorized Logistic Loss Function

|                         |                         |
| -----------------------:| ----------------------- |
|   Turn-in directory :   |  ex03                   |
|   Files to turn in :    |  vec_log_loss.py        |
|   Forbidden functions : |  None                   |
|   Remarks :             |  n/a                    |

## Objectives:

Now that you understood how we can calculate the loss, you will see how to do it with vectorized operations.
The goal of this exercise is to produce the same result as in ex01 but this time you will use NumPy ndarrays.

You must implement the following formula as a function:  

$$
J( \theta) = -\frac{1} {m} \lbrack y \cdot log(h) + (1 - y) \cdot log(1 - h)\rbrack
$$

Where:  
* $J( \theta)$ is the cost function with theta being the weights.
* $m$ is the length of $y$, i.e. the number of observations in our sample.
* $h$ also called y_pred or y_hat, is the calculated hypothesis and it represents the vector of predicted outputs (cf ex01).
* $y$, also called y_true, represents the vector of desired outputs, either 1 or 0.


## Instructions:

In the vec_log_loss.py file create the following function as per the instructions below: 
```python
def vec_log_loss_(y_true, y_pred, m, eps=1e-15):
    """
    Compute the logistic loss value.
    Args:
        y_true: a scalar or a numpy ndarray for the correct labels
        y_pred: a scalar or a numpy ndarray for the predicted labels
        m: the length of y_true (should also be the length of y_pred)
        eps: epsilon (default=1e-15)
    Returns:
        The logistic loss value as a float.
        None on any error.
    Raises:
        This function should not raise any Exception.
    """
```

N.B: you might want to update your sigmoid function to work with NumPy ndarrays ;) !


## Examples:
```python
import numpy as np
from sigmoid import sigmoid_
from vec_log_loss import vec_log_loss_

# Test n.1
x = 4
y_true = 1
theta = 0.5
y_pred = sigmoid_(x * theta)
m = 1   # length of y_true is 1
print(vec_log_loss_(y_true, y_pred, m))     
# 0.12692801104297152

# Test n.2
x = np.array([1, 2, 3, 4])
y_true = 0
theta = np.array([-1.5, 2.3, 1.4, 0.7])
y_pred = sigmoid_(np.dot(x, theta))
m = 1
print(vec_log_loss_(y_true, y_pred, m))     
# 10.100041078687479

# Test n.3
x_new = np.arange(1, 13).reshape((3, 4))
y_true = np.array([1, 0, 1])
theta = np.array([-1.5, 2.3, 1.4, 0.7])
y_pred = sigmoid_(np.dot(x_new, theta))
m = len(y_true)
print(vec_log_loss_(y_true, y_pred, m))     
# 7.233346147374828
```
