 # Exercise 10 - Confusion Matrix

|                         |                         |
| -----------------------:| ----------------------- |
|   Turn-in directory :   |  ex10                   |
|   Files to turn in :    |  confusion_matrix.py    |
|   Forbidden functions : |  None                   |
|   Remarks :             |  n/a                    |

## Objectives:

The goal of this exercise is to recreate the function confusion_matrix of sklearn.metrics and to learn what does the confusion matrix represent.


## Instructions:

For the sake of simplicity, we will only ask you to have three parameters.
Be careful to respect the order, true labels are rows and predicted labels are columns:

```
#                      [predicted labels]    
#                       label_1  label_2
#   [ true ]  label_1         .        .
#   [labels]  label_2         .        .
```

In the confusion_matrix.py file create the following function as per the instructions below:
```python
def confusion_matrix_(y_true, y_pred, labels=None):
    """
    Compute confusion matrix to evaluate the accuracy of a classification.
    Args:
        y_true: a scalar or a numpy ndarray for the correct labels
        y_pred: a scalar or a numpy ndarray for the predicted labels
        labels: optional, a list of labels to index the matrix. This may be used to reorder or select a subset of labels. (default=None)
    Returns: 
        The confusion matrix as a numpy ndarray.
        None on any error.
    Raises:
        This function should not raise any Exception.
    """
```


## Examples:

```python
import numpy as np
from confusion_matrix import confusion_matrix_
from sklearn.metrics import confusion_matrix

y_pred = np.array(['norminet', 'dog', 'norminet', 'norminet', 'dog', 'bird'])
y_true = np.array(['dog', 'dog', 'norminet', 'norminet', 'dog', 'norminet'])
print(confusion_matrix_(y_true, y_pred))
print(confusion_matrix(y_true, y_pred))
# [[0 0 0]
#  [0 2 1]
#  [1 0 2]]
# [[0 0 0]
#  [0 2 1]
#  [1 0 2]]
print(confusion_matrix_(y_true, y_pred, labels=['dog', 'norminet']))
print(confusion_matrix(y_true, y_pred, labels=['dog', 'norminet']))
# [[2 1]
#  [0 2]]
# [[2 1]
#  [0 2]]
```


## Optional part

### Objective(s):

For a more visual version, you can add the option to your previous confusion_matrix_ function to return a Pandas dataframe instead of a NumPy array.

### Instructions:

In the confusion_matrix.py file create the following function as per the instructions below:
```python
def confusion_matrix_(y_true, y_pred, labels=None, df_option=False):
    """
    Compute confusion matrix to evaluate the accuracy of a classification.
    Args:
        y_true: a scalar or a numpy ndarray for the correct labels
        y_pred: a scalar or a numpy ndarray for the predicted labels
        labels: optional, a list of labels to index the matrix. This may be used to reorder or select a subset of labels. (default=None)
        df_option: optional, if set to True the function will return a pandas dataframe instead of a numpy array. (default=False)
    Returns: 
        The confusion matrix as a numpy ndarray or a pandas dataframe according to df_option value.
        None on any error.
    Raises:
        This function should not raise any Exception.
    """
```

### Examples:

```python
import numpy as np
from confusion_matrix import confusion_matrix_

y_pred = np.array(['norminet', 'dog', 'norminet', 'norminet', 'dog', 'bird'])
y_true = np.array(['dog', 'dog', 'norminet', 'norminet', 'dog', 'norminet'])
print(confusion_matrix_(y_true, y_pred, df_option=True))
#           bird  dog  norminet
# bird         0    0         0
# dog          0    2         1
# norminet     1    0         2
print(confusion_matrix_(y_true, y_pred, labels=['bird', 'dog'], df_option=True))
#           bird  dog
# bird         0    0
# dog          0    2
```

N.B: if you fail this exercise on your first attempt, norminet will curse you forever. Yeah, you better do it right or you are in trouble my friend, big trouble!
