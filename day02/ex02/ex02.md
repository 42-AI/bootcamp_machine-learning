# Exercise 04 - Logistic Gradient

|                         |                         |
| -----------------------:| ----------------------- |
|   Turning directory :   |  ex02                   |
|   Files to turn in :    |  log_grad.py            |
|   Forbidden library :   |  Numpy                  |
|   Remarks :             |  n/a                    |

You must implement the following formula as a function:  
 
 $$
{\displaystyle {\overrightarrow {\nabla }}} = \sum_{i = 1}^{m} (h_\theta (x^{(i)}) - y^{(i)}) \cdot x^{(i)} 
 $$
 
 Where:
 ${\displaystyle {\overrightarrow {\nabla }}}$ is the gradient
- x are the input coefficients
- m is the length of y, i.e. the number of observations in our sample
- hθ(x) , also called y_hat or y_pred, is the calculated hypothesis and it represents the predicted output
- y, also called y_true, represents the desired output, either 1 or 0.

We will use the gradient later to update our weights (θ) with respect to the learning rate (α).

Create a me called `log_grad` which takes three arguments:

```python
def log_grad_(x, y_true, y_pred):
```
  - x: a vector or a matrix
  - y_true: a scalar value or a vector for the desired output
  - y_pred: a scalar value or a vector for the hypothesis
  - returns: a scalar value or a vector of the width of x
  
x length (shape[0]) should match y_true and y_pred length, i.e. we should have the same
number of observations.<br>
x width (shape[1]) will be 1 (for the intercept) + the number of coefficients. 
It should match theta length, but this is for later when we will update theta in our gradient descent algorithm.


```python
from sigmoid import sigmoid_
from log_grad import log_grad_

# Test n.1
x = [1, 4.2]  # 1 represent the intercept
y_true = 1
theta = [0.5, -0.5]
x_dot_theta = sum([a*b for a, b in zip(x, theta)])
y_pred = sigmoid_(x_dot_theta)
print(log_grad_(x, y_pred, y_true))         
# [0.8320183851339245, 3.494477217562483]

# Test n.2
x = [1, -0.5, 2.3, -1.5, 3.2]
y_true = 0
theta = [0.5, -0.5, 1.2, -1.2, 2.3]
x_dot_theta = sum([a*b for a, b in zip(x, theta)])
y_pred = sigmoid_(x_dot_theta)
print(log_grad_(x, y_true, y_pred))         
# [0.99999685596372, -0.49999842798186, 2.299992768716556, -1.4999952839455801, 3.1999899390839044]

# Test n.3
x_new = [[1, 2, 3, 4, 5], [1, 6, 7, 8, 9], [1, 10, 11, 12, 13]]
# first column of x_new are intercept values initialized to 1
y_true = [1, 0, 1]
theta = [0.5, -0.5, 1.2, -1.2, 2.3]
x_new_dot_theta = []
for i in range(len(x_new)):
    my_sum = 0
    for j in range(len(x_new[i])):
        my_sum += x_new[i][j] * theta[j]
    x_new_dot_theta.append(my_sum)
y_pred = sigmoid_(x_new_dot_theta)
print(log_grad_(x_new, y_true, y_pred))     
# [0.9999445100449934, 5.999888854245219, 6.999833364290213, 7.999777874335206, 8.999722384380199]
```
