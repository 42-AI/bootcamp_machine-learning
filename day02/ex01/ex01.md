# Exercise 01 - Logistic Loss Function

|                         |                         |
| -----------------------:| ----------------------- |
|   Turn-in directory :   |  ex01                   |
|   Files to turn in :    |  log_loss.py            |
|   Forbidden libraries : |  NumPy                  |
|   Remarks :             |  n/a                    |

## Objectives:

The goal of this exercise is that you understand the logistic loss function and why we use it over MSE loss function.


## Instructions:

You must implement the following formula as a function:  

$$
J( \theta) = -\frac{1} {m} \lbrack \sum_{i = 1}^{m} y^{(i)}log(h_{ \theta }(x^{(i)})) + (1 - y^{(i)})log(1 - h_{ \theta }(x^{(i)}))\rbrack
$$

Where:  
* $J( \theta)$ is the cost function with theta being the weights.
* $m$ is the length of $y$, i.e. the number of observations in our sample.
* $h_{\theta}(x)$ also called y_pred or y_hat, is the calculated hypothesis and it represents the predicted output (formula below).
* $y$, also called y_true, represents the desired output, either 1 or 0.


This function is called the Cross-Entropy loss or logistic loss.
We encourage you to get a look at [**this section**](https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_error_function_and_logistic_regression) of the Cross entropy Wikipedia.

Formula for hypothesis:

$$
\hat{y} = h_{ \theta }(x) = \frac{1} {1 + e^{-\theta \cdot x}}
$$

As you may have noticed, this is our sigmoid function with $\theta \cdot x$ as argument.


In the log_loss.py file create the following function as per the instructions below: 
```python
def log_loss_(y_true, y_pred, m, eps=1e-15):
    """
    Compute the logistic loss value.
    Args:
        y_true: a scalar or a list for the correct labels
        y_pred: a scalar or a list for the predicted labels
        m: the length of y_true (should also be the length of y_pred)
        eps: epsilon (default=1e-15)
    Returns:
        The logistic loss value as a float.
        None on any error.
    Raises:
        This function should not raise any Exception.
    """
```

### Hint:
The purpose of epsilon (eps) is to avoid log(0) errors, it is a very small residual value we add to y_pred.

N.B.: the length y_pred and y_true MUST be the same!


## Examples:

```python
from sigmoid import sigmoid_
from log_loss import log_loss_

# Test n.1
x = 4
y_true = 1
theta = 0.5
y_pred = sigmoid_(x * theta)
m = 1   # length of y_true is 1
print(log_loss_(y_true, y_pred, m))
# 0.12692801104297152

# Test n.2
x = [1, 2, 3, 4]
y_true = 0
theta = [-1.5, 2.3, 1.4, 0.7]
x_dot_theta = sum([a*b for a, b in zip(x, theta)])
y_pred = sigmoid_(x_dot_theta)
m = 1
print(log_loss_(y_true, y_pred, m))
# 10.100041078687479

# Test n.3
x_new = [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]
y_true = [1, 0, 1]
theta = [-1.5, 2.3, 1.4, 0.7]
x_dot_theta = []
for i in range(len(x_new)):
    my_sum = 0
    for j in range(len(x_new[i])):
        my_sum += x_new[i][j] * theta[j]
    x_dot_theta.append(my_sum)
y_pred = sigmoid_(x_dot_theta)
m = len(y_true)
print(log_loss_(y_true, y_pred, m))
# 7.233346147374828
```
