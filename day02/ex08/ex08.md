 # Exercise 08 - Recall

|                         |                         |
| -----------------------:| ----------------------- |
|   Turn-in directory :   |  ex08                   |
|   Files to turn in :    |  recall.py              |
|   Forbidden functiona : |  None                   |
|   Remarks :             |  n/a                    |

## Objectives:

The goal of this exercise is to recreate the function recall_score of sklearn.metrics and to learn what does the recall represent and how to measure it.


## Instructions:

For the sake of simplicity, we will only ask you to have three parameters.

In the recall.py file create the following function as per the instructions below:
```python
def recall_score_(y_true, y_pred, pos_label=1):
    """
    Compute the recall score.
    Args:
        y_true: a scalar or a numpy ndarray for the correct labels
        y_pred: a scalar or a numpy ndarray for the predicted labels
        pos_label: str or int, the class on which to report the precision_score (default=1)
    Returns: 
        The recall score as a float.
        None on any error.
    Raises:
        This function should not raise any Exception.
    """
```


## Examples:

```python
import numpy as np
from recall import recall_score_
from sklearn.metrics import recall_score 

# Test n.1
y_pred = np.array([1, 1, 0, 1, 0, 0, 1, 1])
y_true = np.array([1, 0, 0, 1, 0, 1, 0, 0])
print(recall_score_(y_true, y_pred))
print(recall_score(y_true, y_pred))
# 0.6666666666666666
# 0.6666666666666666

# Test n.2
y_pred = np.array(['norminet', 'dog', 'norminet', 'norminet', 'dog', 'dog', 'dog', 'dog'])
y_true = np.array(['dog', 'dog', 'norminet', 'norminet', 'dog', 'norminet', 'dog', 'norminet'])
print(recall_score_(y_true, y_pred, pos_label='dog'))
print(recall_score(y_true, y_pred, pos_label='dog'))
# 0.75
# 0.75

# Test n.3
print(recall_score_(y_true, y_pred, pos_label='norminet'))
print(recall_score(y_true, y_pred, pos_label='norminet'))
# 0.5
# 0.5
```
