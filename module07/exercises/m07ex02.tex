\chapter{Exercise 02}
\input{exercises/en.ex02_interlude.tex}
\newpage
\extitle{Vectorized Loss Function}
\turnindir{ex02}
\exnumber{02}
\exfiles{loss.py}
\exforbidden{None}
\makeheaderfilesforbidden

% ================================= %
\section*{Objective}
% --------------------------------- %
Understand and manipulate loss function for multivariate linear regression.\\
\newline
You must implement the following formula as a function:  

$$
\begin{matrix}
J(\theta) &  = & \frac{1}{2m}(\hat{y} - y) \cdot(\hat{y}- y)
\end{matrix}
$$  
Where:
\begin{itemize}
  \item $\hat{y}$ is a vector of dimension $m$, the vector of predicted values
  \item $y$ is a vector of dimension $m$, the vector of expected values
\end{itemize}
% ================================= %
\section*{Instructions}
% --------------------------------- %
In the \texttt{loss.py} file create the following function as per the instructions given below:\\
\newline
\begin{minted}[bgcolor=darcula-back,formatcom=\color{lightgrey},fontsize=\scriptsize]{python}
def loss_(y, y_hat):
    """Computes the mean squared error of two non-empty numpy.array, without any for loop.
    The two arrays must have the same dimensions.
    Args:
      y: has to be an numpy.array, a vector.
      y_hat: has to be an numpy.array, a vector.
    Return:
      The mean squared error of the two vectors as a float.
      None if y or y_hat are empty numpy.array.
      None if y and y_hat does not share the same dimensions.
      None if y or y_hat is not of expected type.
    Raises:
      This function should not raise any Exception.
    """
    ... Your code ...
\end{minted}
\newpage
% ================================= %
\section*{Examples}
% --------------------------------- %
\begin{minted}[bgcolor=darcula-back,formatcom=\color{lightgrey},fontsize=\scriptsize]{python}
import numpy as np
X = np.array([0, 15, -9, 7, 12, 3, -21]).reshape((-1, 1))
Y = np.array([2, 14, -13, 5, 12, 4, -19]).reshape((-1, 1))

# Example 1:
loss_(X, Y)
# Output:
2.142857142857143

# Example 2:
loss_(X, X)
# Output:
0.0
\end{minted}