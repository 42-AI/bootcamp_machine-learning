%******************************************************************************%
%                                                                              %
%                                 Interlude                                    %
%                         for Machine Learning module                          %
%                                                                              %
%******************************************************************************%

% ============================================== %
\section*{Interlude}
% ============================================== %
\subsection*{Linear Regression to the Next Level: Ridge Regression}
% ---------------------------------------------- %

Until now we only talked about L$_2$ regularization and its implication on the calculation of the loss function and gradient for both linear and logistic regression.

Now it's time to use proper terminology:
When we apply L$_2$ regularization on a linear regression model, the new model is called a \textbf{Ridge Regression} model.
Besides that brand-new name, Ridge regression is nothing more than linear regression regularized with L$_2$.

We suggest you watch this nice explanation \href{https://www.youtube.com/watch?v=Q81RR3yKn30}{very nice explanation of Ridge Regularization}.
By the way, this Youtube channel, \texttt{\textit{StatQuest}}, is very good to help you understand the gist of a lot of machine learning concepts.
You will not waste your time watching its statistics and machine learning playlists!
