# Exercise 10 - Practicing Ridge Regression

|                         |                     |
| -----------------------:| ------------------  |
|   Turn-in directory :   |  ex10               |
|   Files to turn in :    |  polynomial_ridge.py      |
|   Authorized modules :  |  numpy              |
|   Forbidden modules :   |  sklearn            |

## Objectives:  
It's training time!  
Let's practice our brand new Ridge Regression over train some polynomial model.

## Instructions:

### Part 1: Training
- Take your `spacecraft_data.csv` dataset and train **one** separate Linear Regression models and **nine** Ridge Regression models with polynomial hypotheses with **degree 3**. The Ridge Regression models will be  trained using a range [0.1, 1] of values for $\lambda$. 
- Evaluate the cost of each of the ten models.  
- To properly visualize your results, make a bar plot showing the cost of the models given their $\lambda$ value.   

According to your evaluations, what is the best hypothesis (or model) you can get?

### Part 2: Plots
* For each model you built in the part 1, plot its hypothesis function $h(\theta)$ on top of a scatter plot of the original data points $(x,y)$. 