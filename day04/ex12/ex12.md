# Exercise 12 - Practicing Ridge regression

|                         |                     |
| -----------------------:| ------------------  |
|   Turn-in directory :   |  ex12               |
|   Files to turn in :    |  polynomial_log_reg.py      |
|   Authorized modules :  |  numpy              |
|   Forbidden modules :   |  sklearn            |

## Objectives:  
It's training time!  
Let's practice our brand new Ridge Regression over train some polynomial model.

## Instructions:

### Part 1: Training
- Take your `solar_system_census.csv` dataset and train **ten** separate Logistic Regression models with polynomial hypotheses with **degree 3**. The Logistic Regression models will be  trained using a range [0, 1] of values for $\lambda$. 
- Evaluate the cost of each of the ten models.  
- To properly visualize your results, make a bar plot showing the cost of the models given their $\lambda$ value.   

According to your evaluations, what is the best hypothesis (or model) you can get?

### Part 2: Plots
* For each model you built in the part 1, plot its hypothesis function $h(\theta)$ on top of a scatter plot of the original data points $(x,y)$. 