# Day04 - Regularization
Today you will fight overfitting!  
You will discover the concepts of regularization and how to implement it into the algortihms you already saw until now. 

## Notions of the Day
Regularization, overfitting. Regularized cost function, regularized gradient descent.  
Regularized linear regression. Regularized logistic regression.

## Useful Ressources  
  
We strongly advise you to use the following resource:
[Machine Learning MOOC - Stanford](https://www.coursera.org/learn/machine-learning/home/week/3)  
Here are the sections of the MOOC that are relevant for today's exercises: 

### Week 3: 

**Solving the Problem of Overfitting:**
* Classification (Video + Reading)
* Hypothesis Representation (Video + Reading)
* Decision Boundary (Video + Reading)

**Logistic Regression Model:**
* Cost Function (Video + Reading)
* Simplified Cost Function and Gradient Descent (Video + Reading)
 
**Multiclass Classification:**
* Mutliclass Classification: One-vs-all (Video + Reading)

* Review (Reading + Quiz)

## General rules

* The Python version to use is 3.7, you can check with the following command: `python -V`
* The norm: during this bootcamp you will follow the [Pep8 standards](https://www.python.org/dev/peps/pep-0008/)
* The function `eval` is never allowed.
* The exercises are ordered from the easiest to the hardest.
* Your exercises are going to be evaluated by someone else, so make sure that your variable names and function names are appropriate and civil. 
* Your manual is the internet.
* You can also ask questions in the `#bootcamps` channel in [42AI's Slack workspace](https://42-ai.slack.com).
* If you find any issues or mistakes in this document, please create an issue on our [dedicated Github repository](https://github.com/42-AI/bootcamp_machine-learning/issues).

## Helper

Ensure that you have the right Python version.

```
> which python
/goinfre/miniconda/bin/python
> python -V
Python 3.7.*
> which pip
/goinfre/miniconda/bin/pip
```

### Exercise 00 - Logistic Regression

### Exercise 01 - Polynomial models

### Exercise 02 - Ai Key Notions

### Exercise 03 - Polynomial models II

### Interlude - Fighting overfitting... enter Regularization

### Interlude - Answers to the vectorization problem

### Exercise 04 - L2 Regularization

### Interlude - Predict II: Hypothesis

### Exercise 05 - Regularized Linear Cost Function

### Exercise 06 - Regularized Logistic Cost Function

### Interlude - Regularized Gradient

### Exercise 07 - Regularized Linear Gradient

### Exercise 08 - Regularized Logistic Gradient

### Interlude - Linear Regression to the next level: Ridge Regression

### Exercise 09 - Ridge Regression

### Exercise 10 - Practicing Ridge Regression

### Interlude - Regularized Logistic Regression is still Logistic Regression

### Exercise 11 -  Regularized Logistic Regression

### Exercise 12 - Practicing Regularized Logistic Regression
