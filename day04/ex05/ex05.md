# Exercise 05 - Regularized Logistic Loss Function

|                         |                         |
| -----------------------:| ----------------------- |
|   Turning directory :   |  ex05                   |
|   Files to turn in :    |  reg_log_loss.py        |
|   Forbidden function :  |  None                   |
|   Remarks :             |  n/a                    |

**Objectives:**

You must implement the following formula as a function:  

$$
J(\theta) = \frac{1}{m}\left((-y \cdot \log(h)) - (1 - y) \cdot (1 - log(h))  + \lambda \theta \dot \theta\right) 

J(\theta) = \frac{1}{m}\left((-y^{T}\log(h)) - (1 - y)^{T} (1 - log(h)) + \lambda \theta \dot \theta\right)
$$

where:
- $h = g(X\theta)$ is a vector of dimension m * 1,
- $\theta$ is a vector of dimension n * 1,
- $y$ is a vector of dimension m * 1,
- $\lambda$ is a constant,

**Instructions:**

In the vec_log_loss.py file create the following function as per the instructions below: 
```python
def reg_log_loss_(y_true, y_pred, m, lambda_):
    """
    Compute the logistic loss value.
    Args:
        y_true: a scalar or a numpy ndarray for the correct labels
        y_pred: a scalar or a numpy ndarray for the predicted labels
        m: the length of y_true (should also be the length of y_pred)
        lambda_: a float for the regularization parameter
        eps: epsilon (default=1e-15)
    Returns:
        The logistic loss value as a float.
        None on any error.
    Raises:
        This function should not raise any Exception.
    """
```


**Examples:**
```python
import numpy as np
from sigmoid import sigmoid_
from reg_log_loss import reg_log_loss_

# Test n.1
x_new = np.arange(1, 13).reshape((3, 4))
y_true = np.array([1, 0, 1])
theta = np.array([-1.5, 2.3, 1.4, 0.7])
y_pred = sigmoid_(np.dot(x_new, theta))
m = len(y_true)
print(reg_log_loss_(y_true, y_pred, m, theta, 0.0))     
# 7.233346147374828

# Test n.2
x_new = np.arange(1, 13).reshape((3, 4))
y_true = np.array([1, 0, 1])
theta = np.array([-1.5, 2.3, 1.4, 0.7])
y_pred = sigmoid_(np.dot(x_new, theta))
m = len(y_true)
print(reg_log_loss_(y_true, y_pred, m, theta, 0.5))     
# 7.441471049799478

# Test n.3
x_new = np.arange(1, 13).reshape((3, 4))
y_true = np.array([1, 0, 1])
theta = np.array([-1.5, 2.3, 1.4, 0.7])
y_pred = sigmoid_(np.dot(x_new, theta))
m = len(y_true)
print(reg_log_loss_(y_true, y_pred, m, theta, 1)) 

# 8.065846049799477

# Test n.4
x_new = np.arange(1, 13).reshape((3, 4))
y_true = np.array([1, 0, 1])
theta = np.array([-5.2, 2.3, -1.4, 8.9])
y_pred = sigmoid_(np.dot(x_new, theta))
m = len(y_true)
print(reg_log_loss_(y_true, y_pred, m, theta, 1))     
# 11.478071825561033

# Test n.5
x_new = np.arange(1, 13).reshape((3, 4))
y_true = np.array([1, 0, 1])
theta = np.array([-5.2, 2.3, -1.4, 8.9])
y_pred = sigmoid_(np.dot(x_new, theta))
m = len(y_true)
print(reg_log_loss_(y_true, y_pred, m, theta, 0.3))     
# 12.329321825561033

# Test n.6
x_new = np.arange(1, 13).reshape((3, 4))
y_true = np.array([1, 0, 1])
theta = np.array([-5.2, 2.3, -1.4, 8.9])
y_pred = sigmoid_(np.dot(x_new, theta))
m = len(y_true)
print(reg_log_loss_(y_true, y_pred, m, theta, 0.9))     
# 19.139321825561034
```