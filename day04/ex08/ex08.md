# Exercise 08 - Regularized Logistic Gradient

|                         |                    |
| -----------------------:| ------------------ |
|   Turn-in directory :   |  ex08              |
|   Files to turn in :    |  reg_logistic_grad.py|
|   Authorized modules :  |  Numpy             |
|   Forbidden modules :   |  sklearn           |

## Objectives 
You must implement the following formulas as a functions for the **logistic regression hypothesis**:

### I - Iterative:

$$
\nabla(J)_0 = \frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)}) - y^{(i)})
$$
$$
\nabla(J)_j = \frac{1}{m}\left(\sum_{i=1}^{m}(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} + \lambda \theta_j\right) \text{ for j = 1, ..., n}
$$

Where:  
- $\nabla(J)_j$ is the $j^{th}$ component of $\nabla(J)$,
- $\nabla(J)$ is a vector of dimension $(n + 1) * 1$, the gradient vector,
- $m$ is a constant, the number of training examples used,
- $h_\theta(x^{(i)})$ is the model's prediction for the $i^{th}$ training example,
- $x^{(i)}$ is the feature vector (of dimension $n * 1$) of the $i^{th}$ training example, found in the $i^{th}$ row of the $X$ matrix,
- $X$ is a matrix of dimension $m * n$, the design matrix,
- $y^{(i)}$ is the $i^{th}$ component of the $y$ vector,
- $y$ is a vector of dimension $m * 1$, the vector of expected values,
- $\lambda$ is a constant, the regularization hyperparameter,
- $\theta_j$ is the $j^{th}$ parameter of the $\theta$ vector,
- $\theta$ is a vector of dimension $(n + 1) * 1$, the parameter vector,

### II - Vectorized:
$$
\nabla(J) = \frac{1}{m} [X'^T(h_\theta(X) - y) + \lambda \theta']
$$  

Where:  
- $\nabla(J)$ is a vector of dimension $(n + 1) * 1$, the gradient vector,
- $m$ is a constant, the number of training examples used,
- $X$ is a matrix of dimension $m * n$, the design matrix,
- $X'$ is a matrix of dimension $m * (n + 1)$, the design matrix onto which a column of ones is added as a first column,
- $X'^T$ is the transpose of tha matrix, with dimensions $(n + 1) * m$,
- $h_\theta(X)$ is a vector of dimension $m * 1$, the vector of predicted values, 
- $y$ is a vector of dimension $m * 1$, the vector of expected values,
- $\lambda$ is a constant, the regularization hyperparameter,
- $\theta$ is a vector of dimension $(n + 1) * 1$, the parameter vector,
- $\theta'$ is a vector of dimension $n * 1$, constructed using the following rules: 

$$
\begin{matrix}
\theta'_0 & =  0 \\
\theta'_j & =  \theta_j & \text{ for } j = 1, \dots, n\\    
\end{matrix}
$$


## Instructions:
In the `reg_logistic_grad.py` file, create the following function as per the instructions given below:
```python
def reg_logistic_grad(y, x, theta, lambda_):
    """Computes the regularized logistic gradient of three non-empty numpy.ndarray, with two for-loops. The three arrays must have compatible dimensions.
    Args:
      y: has to be a numpy.ndarray, a vector of dimension m * 1.
      x: has to be a numpy.ndarray, a matrix of dimesion m * n.
      theta: has to be a numpy.ndarray, a vector of dimension n * 1.
      lambda_: has to be a float.
    Returns:
      A numpy.ndarray, a vector of dimension n * 1, containing the results of the formula for all j.
      None if y, x, or theta are empty numpy.ndarray.
      None if y, x or theta does not share compatibles dimensions.
    Raises:
      This function should not raise any Exception.
    """

def vec_reg_logistic_grad(y, x, theta, lambda_):
    """Computes the regularized logistic gradient of three non-empty numpy.ndarray, without any for-loop. The three arrays must have compatible dimensions.
    Args:
      y: has to be a numpy.ndarray, a vector of dimension m * 1.
      x: has to be a numpy.ndarray, a matrix of dimesion m * n.
      theta: has to be a numpy.ndarray, a vector of dimension n * 1.
      lambda_: has to be a float.
    Returns:
      A numpy.ndarray, a vector of dimension n * 1, containing the results of the formula for all j.
      None if y, x, or theta are empty numpy.ndarray.
      None if y, x or theta does not share compatibles dimensions.
    Raises:
      This function should not raise any Exception.
    """
```
**Hint:** this is a great occasion to practice using decorators...

## Examples
```python
x = np.array([[0, 2, 3, 4], 
              [2, 4, 5, 5], 
              [1, 3, 2, 7]])
y = np.array([[0], [1], [1]])
theta = np.array([[-2.4], [-1.5], [0.3], [-1.4], [0.7]])

# Example 1.1:
reg_logistic_grad(y, x, theta, 1)
# Output:
array([[-0.55711039],
       [-1.40334809],
       [-1.91756886],
       [-2.56737958],
       [-3.03924017]])

# Example 1.2:
vec_reg_logistic_grad(y, x, theta, 1)
# Output:
array([[-0.55711039],
       [-1.40334809],
       [-1.91756886],
       [-2.56737958],
       [-3.03924017]])

# Example 2.1:
reg_logistic_grad(y, x, theta, 0.5)
# Output:
array([[-0.55711039],
       [-1.15334809],
       [-1.96756886],
       [-2.33404624],
       [-3.15590684]])

# Example 2.2:
vec_reg_logistic_grad(y, x, theta, 0.5)
# Output:
array([[-0.55711039],
       [-1.15334809],
       [-1.96756886],
       [-2.33404624],
       [-3.15590684]])

# Example 3.1:
reg_logistic_grad(y, x, theta, 0.0)
# Output:
array([[-0.55711039],
       [-0.90334809],
       [-2.01756886],
       [-2.10071291],
       [-3.27257351]])

# Example 3.2:
vec_reg_logistic_grad(y, x, theta, 0.0)
# Output:
array([[-0.55711039],
       [-0.90334809],
       [-2.01756886],
       [-2.10071291],
       [-3.27257351]])
```
