# Exercise 03 - Understanding the Mathematical Concepts

|                         |                    |
| -----------------------:| ------------------ |
|   Turn-in directory :   |  ex03              |
|   Files to turn in :    |  answers.txt       |
|   Forbidden modules :   |  NA                |
|   Forbidden functions : |  NA                |
|   Remarks :             |  Read the doc      |


## Objectives:

The aim of this exercise is to check your understanding of the three key mathematical concepts for Decision Trees:
- Gini impurity of a dataset.
- Shannon entropy of a dataset.
- Information gain between two datasets.


## Instructions:

In the answers.txt file, answer the following questions in 3 sentences maximum. The idea is to understand the underlying concepts. These are simple questions (no traps!)
1) Define what Gini impurity is about and what it measures. (No mathematical formula, just the general concept in words).
2) Define what Shannon entropy is and what it measures. (No mathematical formula, just the general concept in words).
3) Define what Information gain is and what it measures. (No mathematical formula, just the general concept in words).
4) Explain how these 3 concepts are used for decision trees. 
5) If the dataset has 2 classes, explain what are the boundaries (minimum and maximum) of Gini impurity and Shannon entropy.
6) What does it mean if the Gini impurity is 0? If Shannon entropy is 0?


## Bonus questions:
7) Why should you use Gini impurity as default?
8) What are the pros and cons of just using the criteria Information Gain positive or negative to pick the feature of a decision tree? Can we mitigate this risk?
