# Exercise 1 - Linear Regression

|                         |                    |
| -----------------------:| ------------------ |
|   Turnin directory :    |  ex00              |
|   Files to turn in :    |  linear\_model.py  |
|   Authorize module :    |  numpy, matplotlib |
|   Forbidden module :    |  sklearn           |
|   Forbidden function :  |  LinearRegression  |
|   Remarks :             |  Read the doc      |

**Objectives:** 

* Reinforce the mathematical skills tackled in **Mathematical Delights**, especially the __linear cost function__ and __gradient descent__.
* Be able to explain what is the __linear cost function__ and the __linear gradient descent__.

* Be able to implement basic methods in order to perform a linear regressions.


**Instructions:**

You can find in the ressources a tiny data set called __is_blue_pills_are_magic.csv__ which give you mathematical performance of patients in function of the quantity of the "blue pills" they took before the test.

As hypothesis function h, you will choose:
$$
h(X)= \theta_0x_0 + \theta_1x_1
$$
where $\pmb{X}$ is the vector $(x_0, x_1)$ and $\pmb{theta} = (theta_0, \theta_1)$


You will model the data and plot 3 differents graphs:
* The cost function $J(**\theta**)$ in function of the $\theta$'s values (see example in figure 1),
* The graph with the data and the best hypothesis you find for the spacecraft piloting score versus the quantity of "blue pills" (see example figure 2),
* The MSE associated with your predictions in function of $\theta$'s (see example figure 3).

The MSE is given by the following formula:
$$
MSE = \frac{1}{2M}\sum{i=1}{M}\left(\hat{y}^{(i)} - y^{(i)}\right)^2
$$
where $\hat{y}^{(i)}$ and $y^(i)$ are respectively the predicted output and the output with the ith training samples $x^{(i)}$.

To do so you will implement a class called **MyLinearRegression**  similar to **sklearn.linear\_model.LinearRegression**, containing at least the following methods:
``` python
def predict(self, X):
	"""
	Description:
		Predict using the linear model.
	Args:
		X: __array_like__ or __sparse matrix__, shape(number of training examples, number of features)
		-> Samples(/training dataset) data from which we want to generate predicted values.
	Returns:
		C: array, shape(number of the training examples,)
		-> Predicted values in the form of an array.
	Raises:
		This method should not raise any Exception.
	"""

def score(self, X, Y):
	"""
	Description:
		Calculate the MSE (Mean Squared Error) of the set of predicted values with respect to Y.
	Args:
		X: __array_like__ or __sparse matrix__, shape(number of training examples, number of features)
		-> Samples(/training dataset) from which we want to generate predicted values.
		Y: array, shape(number of training examples,)
		->
	Return:
		score: float.
		-> MSE of self.predict(X) with respect to Y.
	"""
```

Be sure to understand the underlying concept and be able to answer to those questions evaluators may ask:
* What is the hypothesis and what is it goal ?
* What is the cost function and what it is representing ?
* What is the linear gradient descent and what is it doing ?
* Can you explain the MSE and what it is spotting ?
