### Gradient Descent

Now we know the direction we should aim in order to reduce our cost function. 
What we have to do next is to move into that direction step after step, until we reach our minimum. This iterative process is called **Gradient Descent**. It is a very common way to improve the performance of algorithms in Machine Learning. 