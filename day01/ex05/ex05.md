# Exercise 05 - Mutiples features and Linear Gradient Descent

|                         |                    |
| -----------------------:| ------------------ |
|   Turn-in directory :   |  ex05              |
|   Files to turn in :    |  multi_linear\_model.py  |
|   Authorized modules :  |  NumPy, Matplotlib |
|   Forbidden modules :   |  sklearn           |
|   Forbidden functions : |  LinearRegression  |
|   Helpful links :       |  [Machine Learning Mooc / Week 2](https://www.coursera.org/learn/machine-learning/home/week/2) |
|   Hint :                | Really, spend time on "Multivariate Linear Regression" section until it is clear |

## Objectives:

* Reinforce the mathematical skills tackled in **Mathematical Delights**, especially the vectorized form of __linear cost function__ and __gradient descent__.
* Be able to manipulate the __linear cost function__ and the __linear gradient descent__ for a multiple features problem (and knowing what you are doing of course).
* Be able to visualize the different objects via graphics and extract basic informations based on them.


## Instructions:

As you are able to perform a simple linear regression with one feature (well done!) it is time to dream bigger.
Lucky you are, we give you a new dataset with multiple features that you will find in the ressources attached.
The dataset is called __"spacecraft_data.csv"__ which contains the prices of spacecrafts in function of multiple features (multiple features means you will need a multi-linear model but hold on for the moment). A description of the dataset is provided in the file __"spacecraft_data_description.txt"__.


## Part One: single linear regression

As a starter, you will try to fit the data with a single linear regression and see what we get. Thus, your hypothesis h(X) would be given by:

$$
h(X) = X \cdot \theta = \begin{bmatrix} 1 & x_1^{(1)} \\ \vdots & \vdots \\ 1 & x_1^{(M)}\end{bmatrix}\cdot\begin{bmatrix}\theta_0 \\ \theta_1 \end{bmatrix} = \begin{bmatrix} \theta_0 + \theta_1x_1^{(1)} \\ \vdots \\ \theta_0 + \theta_1x_1^{(M)} \end{bmatrix}
$$

assuming $X$ is an array of dimension (M, N+1) (M corresponding to the number of training examples and N to the number of features). Here in this part 1, N is equal to 1.
As you already noticed, an extra column of 1 is add at the beginning of the X matrix such as the matrix product gives a vector of dimension (M, 1) where the ith component is $\theta_0 + \theta_1x_1^{(i)}$. This is just a trick to perform the calculation of h(X) in the vectorized way.

###Instructions:

You are expected to :
* The graph with the data, the hypothesis $h_{{\theta_0,\theta_{age}}}^{LGD}(age)$ obtained via linear gradient descent versus age (see example figure 1),

<img src="day01/assets/ex05_price_vs_age_part1.png" />

Figure 1: Evolution of the sell price of spacecrafts with respect to the age of the spacecraft and representation of the predicted values of our first model.

* The graph with the data, the hypothesis $h_{{\theta_0,\theta_{thrust}}}^{LGD}(thrust)$ obtained via linear gradient descent versus thrust (see example figure 2),

<img src="day01/assets/ex05_price_vs_thrust_part1.png" />

Figure 2: Evolution of the sell price of spacecrafts with respect to the thrust power of the spacecraft engines and representation of the predicted values of our second model.

* The graph with the data, the hypothesis $h_{{\theta_0,\theta_{Tmeters}}}^{LGD}(Tmeters)$ obtained via linear gradient descent versus Tmeters (see example figure 3),

<img src="day01/assets/ex05_price_vs_Tmeters_part1.png" />

Figure 3: Evolution of the sell price of spacecrafts with respect to the terameters driven and the predicted values of our third model.

### Reminder:

* You may obtain after the fit $\theta$=array([[nan, nan]]). It may come from a too large learning rate.
* Also, be aware that you set the number of cycles of the fitting process, but it does not guarantee that the fit is the best or a good one. For this purpose, a tolerance parameter might be used (not see here, so do not worried).
Here, you can increase the number of cycle and play around with the learning rate to try to get a good fit.

### Hint:

Plot the data in function of the feature you are working with, allows you to guess initial values of theta that are not too bad, which will help to converge to a good fit.

###Examples:

```python
import pandas as pd
import numpy as np
form mylinearregression import MyLinearRegression as MyLR

data = pd.read_csv("spacecraft_data.csv")
[...]
myLR_age = MyLR([[1000.0], [-1.0]])
myLR_age.fit_(X[:,0].reshape(-1,1), Y, alpha = 2.5e-5, n_cycle = 100000)

RMSE_age = myLR_age.mse_(X[:,0].reshape(-1,1),Y)
 print(RMSE_age)
57636.77729...
```
Are the fits with a single variable precised? Why? (What did I say a the beginning?)


## Part Two: Multilinear Regression (A New Hope)

Now, it is time for your first multilinear regression!
As you might expected, the formula of the hyphothesis change a little and is given by:

$$
h(X)= X \theta
  =\begin{bmatrix} x_0^{(1)} & \cdots & x_N^{(1)}\\ \vdots & \ddots & \vdots \\ x_0^{(M)} & \cdots & x_N^{(M)}  \end{bmatrix} \cdot \begin{bmatrix} \theta_0 \\ \vdots \\ \theta_N\end{bmatrix}
  = \begin{bmatrix}\sum_{i=1}^{N}\theta_ix_i^{(1)} \\ \vdots \\ \sum_{i=1}^{N}\theta_ix_i^{(M)} \end{bmatrix}
$$

where $X$ is the training dataset matrix, $\theta$ the coefficients vector, M is the number of training samples and N the number of features.
But It should not change the methods you coded, hopefully!

### Examples:

```python
import pandas as pd
import numpy as np
form mylinearregression import MyLinearRegression as MyLR

data = pd.read_csv("spacecraft_data.csv")
X = np.array(data[['Age','Thrust_power','Terameters']])
Y = np.array(data[['Sell_price']])
my_lreg = MyLR([1.0, 1.0, 1.0, 1.0])

my_lreg.mse_(X,Y)
# 144044.877...

my_lreg.fit_(X,Y, alpha = 1e-4, n_cycle = 600000)
my_lreg.theta
# array([[334.994...],[-22.535...],[5.857...],[-2.586...]])

my_lreg.mse_(X,Y)
# 586.896999...
```

### Remarks:

You can obtain a better fit, if you increase the number of cycles.

You are expected to:
* Plot the output and predicted output on the same graph, in function of the age(see figure below),

<img src="day01/assets/ex05_price_vs_age_part2.png" />

Figure 1: Evolution of the sell prices of spacecrafts and evolution of predicted sell prices of spacecrafts with the multi-variables hypothesis, with respect to the age.

* Plot the output and predicted output on the same graph, in function of the thrust power (see figure below),

<img src="day01/assets/ex05_price_vs_thrust_part2.png" />

Figure 2: Evolution of the sell prices of spacecrafts and the evolution of predicted sell prices of spacecrafts with the multi-variables hypothesis, with respect to the thrust power of the engines.

* Plot the output and predicted output on the same graph, in function of the distance (see figure below),

<img src="day01/assets/ex05_price_vs_Tmeters_part2.png" />

Figure 3: Evolution of the sell prices of spacecrafts and evolution of the predicted sell prices of spacecrafts with multi-variables hypothesis, with respect to the terameters driven.

What conclusion can you make in regards of the results of both parts?


## Questions:

Be sure to understand the underlying concepts and be able to answer those questions during your evaluation:
* What can you say on the influence of the choice of the hypothesis?
