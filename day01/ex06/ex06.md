# Exercise 06 - Mutiples features and Normal Equation

|                         |                    |
| -----------------------:| ------------------ |
|   Turn-in directory :   |  ex06              |
|   Files to turn in :    |  normal_equation_model.py  |
|   Authorized modules :  |  NumPy, Matplotlib |
|   Forbidden modules :   |  sklearn           |
|   Forbidden functions : |  LinearRegression  |
|   Helpful links :       |  [Machine Learning Mooc / Week 2](https://www.coursera.org/learn/machine-learning/home/week/2) |
|   Remarks :             | Take a look to the "Computing Parameters Analytically" section |

## Objectives:

* Reinforce the mathematical skills tackled in **Mathematical Delights**, especially the vectorized form of __matrix-matrix oparations__ (intermediate manipulation).
* Be able to perform  __linear cost function__ and what one names  __normal equation__ for a multiple features problem (and still knowing what you are doing of course obviously).
* Be able to implement a vectorized method **normalequation** in order to perform a full linear regression with the normal equation method.


## Instructions:

We continue to play with the same dataset (__spacraft_data.csv__) given in the previous exercise. 
You will code a new method named **normalequation** which will allows you to perform a fit of the dataset based on the method called __normalequation__.
The normal equation is:

$$
{\theta}_{NE} = \left({X}^{T} {X}\right)^{-1}\cdot{X}^T{Y}
$$

Where $X$ is the training dataset matrix, $\theta_{NE}$ the coefficients vector obtained with the normal equation, $Y$ are the output vector.

__For those who do not understand what the meaning of the superscripts **"T"** and **"-1"** over a matrix, they respectively tell you we take the transpose and the inverse of the concerned matrix.
Do not worry, for those who do not know what it means or do not remember how to do, well you can still do the exercise because numpy will run the maths for you, but you will not understand what happens behind the scene for the moment.
Fortunaly, the mathematic workshops will be coming soon, what a wonderful opportunity to learn to do transposition and inversion of matrices. Lucky you!__

You are expected to:
* Add the method **normalequation_** in the class **__MyLinearRegression__** as per the instructions given below:
```python
def normalequation_(self, X, Y):
	"""
	Description:
		Perform the normal equation to get the theta parameters of the hypothesis h and stock them in self.theta.
	Args:
		X: has to be a numpy.ndarray, a matrix of dimension (number of training examples, number of features)
		Y: has to be a numpy.ndarray, a vector of dimension (number of training examples,1)
	Returns:
		No return expected.
	Raises:
		This method should not raise any Exceptions.
	"""
           ... your code ...
```

You will model the data and plot differents graphs (yes again):
* The graph with the data, the hypothesis $h_{{\theta}}^{LGD}({X})$ obtained via linear gradient descent and $h_{{\theta}}^{NE}({X})$ (see example figure below) with respect to the feature of your choice,

<img src="day01/assets/ex06_sellprice_ne_lgd_vs_age.png" />

* Calculate the MSE between the data and the predicted data generate with the model train with the linear gradient descent, then with normal equation technique.


## Examples:

```python
import pandas as pd
import numpy as np
from mylinearregression import MyLinearRegression as MyLR
data = pd.read_csv("spacecraft_data.csv")
[...]
myLR_ne = MyLR([1., 1., 1., 1.])
myLR_lgd = MyLR([1., 1., 1., 1.])
myLR_lgd.fit_(X,Y, alpha = 5e-5, n_cycle = 10000)
myLR_ne.normalequation_(X,Y)

myLR_lgd.mse_(X,Y)
# 2265.1048...

myLR_ne.mse_(X,Y)
# 413.05299...
```


## Questions:

Be sure to understand the underlying concepts and be able to answer those questions during your evaluation:
* Between the LGD and the NE fits which one is the best model? (quantitative arguments are welcome)
* What are the advantages and drawbacks of the linear gradient descent and normal equation?
* In which case, the method normal equation cannot be used?
