# Exercise 00 - Linear Regression

|                         |                    |
| -----------------------:| ------------------ |
|   Turnin directory :    |  ex00              |
|   Files to turn in :    |  linear\_model.py  |
|   Authorize module :    |  numpy, matplotlib |
|   Forbidden module :    |  sklearn           |
|   Forbidden function :  |  LinearRegression  |
|   Remarks :             |  Read the doc      |

**Objectives:** 

* Reinforce the mathematical skills tackled in **Mathematical Delights**, especially the __matrix-matrix operations__ and __linear gradient__.
* Be able to explain what is the __linear cost function__ and the __gradient descent__.

* Be able to implement basic methods in order to perform a linear regressions.


**Instructions:**

You can find in the ressources a tiny data set called __are_blue_pills_magics.csv__ which give you mathematical performance of patients in function of the quantity of the "blue pills" they took before the test.

As hypothesis function h, you will choose:

$$
h(X)= \theta_0x_0 + \theta_1x_1
$$

Where ${X}$ is the vector $(x_0, x_1)$ and ${theta} = (theta_0, \theta_1)$


You will model the data and plot 2 differents graphs:
* The graph with the data and the best hypothesis you find for the spacecraft piloting score versus the quantity of "blue pills" (see example figure 1),
* The cost function $J(\theta)$ in function of the $\theta$ values (see example in figure 2),

<img src="day01/assets/Figure_1.png" />

Figure 1: Evolution of the space driving score in function of the quantity of blue pill in micrograms.

<img src="day01/assets/Figure_2.png" />

Figure 2: Evolution of the cost function J in fuction of $\theta_0$ and $\theta_1$.

Plus, you will calculate the mean values of the dataset and the MSE of the hypothesis you chose.
The MSE is given by the following formula:

$$
MSE = \frac{1}{2M}\sum{i=1}{M}\left(\hat{y}^{(i)} - y^{(i)}\right)^2
$$

where $\hat{y}^{(i)}$ and $y^{(i)}$ are respectively the predicted output and the real output with the ith training samples $x^{(i)}$.

To do so you will implement a class called **MyLinearRegression**  similar to **sklearn.linear\_model.LinearRegression**, containing the following methods:
``` python
def predict(self, X):
	"""
	Description:
		Predict using the linear model.
	Args:
		X: __array_like__ or __sparse matrix__, shape(number of training examples, number of features)
		-> Samples(/training dataset) data from which we want to generate predicted values.
	Returns:
		C: array, shape(number of the training examples,)
		-> Predicted values in the form of an array.
	Raises:
		This method should not raise any Exception.
	"""

def mse(self, X, Y):
	"""
	Description:
		Calculate the MSE (Mean Squared Error) of the set of predicted values with respect to Y.
	Args:
		X: __array_like__ or __sparse matrix__, shape(number of training examples, number of features)
		-> Samples(/training dataset) from which we want to generate predicted values.
		Y: array, shape(number of training examples,)
		->
	Return:
		mse: float.
		-> MSE of self.predict(X) with respect to Y.
	"""

```

**Examples**
```python
import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error
from mylinearregression import MyLinearRegression as MyLR

data = pd.read_csv("are_blue_pills_magics.csv")
Xpill = np.array(data[micrograms]).reshape(-1,1)
Yscore = np.array(data[Score]).reshape(-1,1)

linear_model_1 = MyLR([89.0, -8])
linear_model_2 = MyLR([89.0, -6])
Y_model1 = linear_model1.predict(Xpill)
Y_model2 = linear_model2.predict(Xpill)

print(linear_model_1.mse(Xpill, Yscore))
# 57.60304285714282
print(mean_squared_error(Yscore, Y_model1))
# 57.603042857142825
print(linear_model_2.mse(Xpill, Yscore))
# 232.16344285714285
print(mean_squared_error(Yscore, Y_model1))
# 232.16344285714285
```

**Clarifications and hints**
There is no method named __.mse__ in the class LinearRegression of the module sklearn.linear_model but there is a method named __.score__. The __.score__ method correspond to the $R^2$ score.
The metric MSE is available in the module sklearn.metrics.


Be sure to understand the underlying concept and be able to answer to those questions evaluators may ask:
* What is the hypothesis and what is it goal ?
* What is the cost function and what it is representing ?
* What is the linear gradient descent and what is it doing ?
* Can you explain the MSE and what it is spotting ?
