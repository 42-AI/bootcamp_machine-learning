# Bonus Exercise - Learning Rate and Quadratic Hypothesis

|                         |                    |
| -----------------------:| ------------------ |
|   Turn-in directory :   |  ex07              |
|   Files to turn in :    |  so_much_hyp.py    |
|                         |  alpha.py          |
|   Authorized modules :  |  NumPy, Matplotlib |
|   Forbidden modules :   |  sklearn           |
|   Forbidden functions : |  LinearRegression  |
|   Helpful links :       | Did I already give you a link to coursera Machine Learning MOOC? |
|   Remarks :             | You know what to look at, I think... |

## Objectives:

* Learn other metrics such as RMSE and R2score, and understand their limits.
* Discover the non-linear dependency to elaborate more complex hypothesis and reinforce mathematical skills at the same time.
* Gain a deeper understanding of the learning rate.


## Instructions:

__ With great power comes great responsability __ (Uncle Ben).
Uncle Ben was right, with a large power thrust comes a risk of spacecraft crash.
With the apparition of individual spacecraft, the number of wild rides increases a lot, especially in the asteroid Saturn Belt.
Experts are concerned with the impact of these rides and worried about the consequence on the number of asteroids orbiting and the number of asteroids leaving the orbit of Saturn!

For this last exercise you have to find a model to describe the number of asteroids leaving the orbit of Saturn due to wild rides.
The dataset related to this important problem is named __"saturn_asteroids.csv"__. The data description is in the file __"saturn_asteroids_description.txt"__.
Also, you have a really nice graphical representations just below.

<img src="day01/assets/ex07_3Dplot_data.png" />

You will use the methods you code during the day to fit the data.
The hypothesis function you will need is a more complex one. This time you have to find out the best model to fit the data.
Do not worry, it is not too complicated.
You have to justify your hypothesis (know what and why you are doing).


## Part Zero - Nothing Else (but) Metrics

This part will focus on the metrics. You already know about one of them: MSE. There are several more which are quite usual: RMSE, MAE and R2score.
In this part you will code 2 more methods you will add to **MyLinearRegression** class: RMSE and R2score, as per the instructions below:
```python
def rmse_(self, X, Y):
	"""
	Description:
		Calculate the RMSE between the predicted output and the real output.
	Args:
		X: has to be a numpy.ndarray, a matrix of dimension (number of training examples, number of features).
		Y: has to be a numpy.ndarray, a vector of dimension (number of training examples, 1).
	Returns:
		rmse: has to be a float.
		None if there is a matching dimension problem.
	Raises:
		This function should not raise any Exception.
	"""
		... your code here ...
def r2score_(self, X, Y):
	"""
	Description:
		Calculate the R2score between the predicted output and the output.
	Args:
		X: has to be a numpy.ndarray, a matrix of dimension (number of training examples, number of features).
		Y: has to be a numpy.ndarray, a vector of dimension (number of training examples, 1).
	Returns:
		r2score: has to be a float.
		None if there is a matching dimension problem.
	Raises:
		This function should not raise any Exception.
	"""
		... your code here ...
```

### Remarks:
You might consider to code 2 more methods **rmse_elem_()** and **r2score_elem_()** similar to what you did for the cost function in the exercise 01.
These methods will help you to evaluate the hypothesis in the following part.


## Part One - Find the best hypothesis

For this part, you will write your code in the file __"so_much_hyp.py"__.
You can code new methods to help you to justify the choice of the hypothesis but it is not compulsory.
The major work for this exercise concerns the data.

You are expected to:
* Find a good hypothesis and justify that your model is a good one. So you have to imagine different hypothesis and try them (see figure below).

<img src="day01/assets/ex07_hypo_test_part1.png" />

### Hints:

Take a look to the metrics (the RMSE for example) with respect to the features.
Notice that the graphs $\sqrt{1/M(\widehat{y^{(i)}} - y^{(i)})^2}$ is not the rmse that we plot precisely, but the term of the sum (**rmse_elem_** ...).

### Examples:

Here, what you can get:
```python
import pandas as pd
import numpy as np
from mylinearregression import MyLinearRegression as MyLR
data = pd.read_csv("saturn_asteroids.csv")
X = np.array(data[['Mean_speed','N_spacecraft']])
Y = np.array(data[['ALSB']])
hypo1 = MyLR([1., 1.])
hypo2 = MyLR([1., 1.])
hypo1.fit_(X[:,0], Y, alpha = 1e-4, n_cycle = 1e5)
hypo2.fit_(X[:,1], Y, alpha = 1e-4, n_cycle = 1e5)

hypo1.rmse_(X[:,0],Y)
# 6.439...

hypo2.rmse_(X[:,0],Y)
# 15.089...
```
Best fit to bet: RMSE = 0.05977051791842336, good luck. Of course, if you are using normal equation, You cannot consider you compete fairly (boo !!).


## Part Two - The learning rate $\alpha$

For this part you will write your code in the file __alpha.py__.
We will focus on the concept of learning rate, in consequence, you will have to fit with the method __MyLinearRegression.fit__ you coded previously.

You are expected to:
* Find a good learning rate $\alpha$ to fit the data with the hypothesis you have chosen in the previous part, you choice will be motivated by the convergence reached in the minimum cycle (see figure below).

<img src="day01/assets/ex07_learning_rate.png" />

Be sure to understand the underlying concept and be able to answer those questions evaluation:
* What happens if you choose a learning rate too big?
* How the metric and the $\theta$'s evolve with a slighly too big learning rate?
* How the convergence evolves in function of the cycle ? Do you have any idea to speed up the convergence as the number of cycle increase? (It is an open question, be creative and smart)
