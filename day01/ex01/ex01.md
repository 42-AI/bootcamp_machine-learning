# Exercise 01 - Cost function Concept

|                         |                     |
| -----------------------:| ------------------  |
|   Turn-in directory :   |  ex01               |
|   Files to turn in :    |  cost_function.py   |
|   Authorized modules :  |  NumPy              |
|   Forbidden functions : |  None               |
|   Helpful links :       |  [Machine Learning Mooc / Week 1](https://www.coursera.org/learn/machine-learning/home/week/1) |
|                         |  [Machine Learning Mooc / Week 2](https://www.coursera.org/learn/machine-learning/home/week/2) |
|   Hint :                |  Focus on the "Model and Cost Function" section of week 1 |
|                         | and "Multivariate Linear Regression" section of week 2"|

## Objectives:

* Reinforce the mathematical skills tackled in **Mathematical Delights**, especially the __matrix-matrix operations__.
* Be able to explain what is the cost function in the machine learning context.
* Be able to implement a basic method based on the hypothesis function and output to obtain the value of the cost function.


## Instructions:

In this exercise you will be interested with the concept of cost function usually noted J. The cost function is defined by the following formula:

$$
J{(\theta)} = \frac{1}{2M}\sum_{i=1}^{M}\left(\hat{y^{(i)}} - y^{(i)}\right)^2 = \frac{1}{2M}\sum_{i=1}^{M}\left(h_{\theta}(X^{(i)}) - y^{(i)}\right)^2
$$

Where :
* $\theta$ is the coefficient vector,
* M is the number of training examples,
* $\hat{y}^{(i)}$ is the ith predicted output.
* $y^{(i)}$ is the ith real output.
* $X^{(i)}$ is the ith training example (line vector of $N$ components),

Then you will code the functions named __cost_elem\___ and __cost\___ as per the instructions below:
``` python
def cost_elem_(theta, X, Y):
	"""
	Description:
		Calculates all the elements (0.5/M)*(y_pred - y)^2 of the cost function.
	Args:
		theta: has to be a numpy.ndarray, a vector of dimension (number of features + 1, 1).
		X: has to be a numpy.ndarray, a matrix of dimension (number of training examples, number of features).
	Returns:
		J_elem: numpy.ndarray, a vector of dimension (number of the training examples,1).
		None if there is a dimension matching problem between X, Y or theta.
	Raises:
		This function should not raise any Exception.
	"""
		... your code here ...

def cost_(theta, X, Y):
	"""
	Description:
		Calculates the value of cost function.
	Args:
		theta: has to be a numpy.ndarray, a vector of dimension (number of features + 1, 1).
		X: has to be a numpy.ndarray, a vector of dimension (number of training examples, number of features).
	Returns:
		J_value : has to be a float.
		None if X does not match the dimension of theta.
	Raises:
		This function should not raise any Exception.
	"""
		... your code here ...
```


## Examples:

```python
import numpy as np
X1 = np.array([[0.], [1.], [2.], [3.], [4.]])
theta1 = np.array([[2.], [4.]])
Y1 = np.array([[2.], [7.], [12.], [17.], [22.]])

cost_elem_(theta1, X1, Y1)
# array([[0.], [0.1], [0.4], [0.9], [1.6]])

cost_(theta1, X1, Y1)
# 3.0

X2 = np.array([[0.2, 2., 20.], [0.4, 4., 40.], [0.6, 6., 60.], [0.8, 8., 80.]])
theta2 = np.array([[0.05], [1.], [1.], [1.]])
Y2 = np.array([[19.], [42.], [67.], [93.]])

cost_elem_(theta2, X2, Y2)
# array([[1.3203125], [0.7503125], [0.0153125], [2.1528125]])

cost_(theta2, X2, Y2)
# 4.238750000000004
```


## Remarks:

You may notice that the cost function is very similar to the MSE (see day00).


## Questions:

Be sure to understand the underlying concepts and be able to answer those questions during your evaluation:
* What is the cost function and what is it goal?
* What is the interest of the cost function derivative (you may look few more videos of the week 2 on Coursera)?
* **Bonus (hard) question :** Are there other forms of the cost function? Cite at least 2 definitions (with formula) of the cost function and give a very short description.

