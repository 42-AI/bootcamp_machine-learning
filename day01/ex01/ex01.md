# Exercise 01 - Mutiples features and Linear Gradient Descent

|                         |                    |
| -----------------------:| ------------------ |
|   Turnin directory :    |  ex01              |
|   Files to turn in :    |  multi_linear\_model.py  |
|   Authorize module :    |  numpy, matplotlib |
|   Forbidden module :    |  sklearn           |
|   Forbidden function :  |  LinearRegression  |
|   Remarks :             |  Read the doc      |

**Objectives:** 

* Reinforce the mathematical skills tackled in **Mathematical Delights**, especially the vectorized form of __linear cost function__ and __gradient descent__.
* Be able to manipulate the __linear cost function__ and the __linear gradient descent__ for a multiple features problem (and knowing what you are doing of course).
* Be able to implement vectorized methods **.fit** and **.rmse** in order to perform a full multi-linear regressions.
* Be able to visualize the different objects via graphics and extract basics informations based on its.


**Instructions:**

As you are able to perform a simple linear regression with one feature (well done!) it is time to dream bigger.
Lucky you are, we give you a new dataset with multiple features that you will find in the ressources attached.
The dataset is called __"spacecraft_data.csv"__ which contains the prices of spacecrafts in function of multiples features (multiple features means you will need a multi-linear model but hold on for the moment). A description of the dataset is provided in the file __"data_description.txt"__.

## Part One: single linear regression

As a starter, you will try to fit the data with a single linear regression and see what we get.
Thus, your hypothesis h(X) would be given by:
$$
h(X) = X \cdot \theta = \begin{bmatrix} 1 & x_1^{(1)} \\ \vdots & \vdots \\ 1 & x_1^{(M)}\end{bmatrix}\cdot\begin{bmatrix}\theta_0 \\ \theta_1 \end{bmatrix} = \begin{bmatrix} \theta_0 + \theta_1x_1^{(1)} \\ \vdots \\ \theta_0 + \theta_1x_1^{(M)} \end{bmatrix}
$$
assuming $X$ is an array of dimension $M \times (N+1)$ (M corresponding to the number of training examples and N to the number of features).
As you can notice, an extra column of 1 is add at the beginning of the X matrix such as the matrix product gives a vector of dimension $M \times 1$ where the ith component is $\theta_0 + \theta_1x_1^{(i)}$. This is just a trick to perform the calculation of h(X) in the vectorized way.

You are expected to:
* Add the methods __.fit__ and __.rmse__ in the class **__MyLinearRegression__** you started to create in the previous exercise (fit by hand is over), following the prototype:
```python
def fit(self, X, Y, alpha = 0.005, n_cycle=10000):
	"""
	Description:
		Fit the linear model by performing a gradient descent on the cost function.
	Args:
		X: has to be a numpy.ndarray, a vector of dimension (number of training examples, number of features).
		Y: has to be a numpy.ndarray, a vector of dimension (number of training examples,1).
		alpha: has to be a float.
		n_cycle: has to be an integer.
	Returns:
		No return
	Raises:
		This method should not raise any Exception.
	"""

def rmse(self, X, Y):
	"""
	Description:
		Calculate the RMSE (Root Mean Squared Error) of the set of predicted values with respect to Y.
	Args:
		X: has to be a numpy.ndarray, a vector of dimension (number of training examples, number of features).
		Y: has to be a numpy.ndarray, a vector of dimension (number of training examples,1).
	Return:
		rmse: has to be a float.
	Raises:
		This method should not raise any Exception.
	"""
```
I strongly encourage you to code the **.fit** and **.rmse** methods in a vectorized way...

You will calcultate the rmse score of your fits for the differents features. You have an example below:
**Examples**
```python
>>>import pandas as pd
>>>import numpy as np
>>>form mylinearregression import MyLinearRegression as MyLR
>>>
>>>data = pd.read_csv("spacecraft_data.csv")
>>>[...]
>>>myRL_age = MyLR([1.0, 1.0])
>>>myLRage.fit(X[:,0].reshape(-1,1),Y)
>>>
>>>RMSE_age = myLRage.rmse(X[:,0].reshape(-1,1),Y)
>>> print(RMSE_age)
131.935...

```

You are expect to plot 6 differents graphs:
* The graph with the data, the hypothesis $h_{{\theta}}^{LGD}(age)$ obtained via linear gradient desent versus age (see example figure 1),
* The graph with the data, the hypothesis $h_{{\theta}}^{LGD}(thrust)$ obtained via linear gradient desent versus thrust (see example figure 2),
* The graph with the data, the hypothesis $h_{{\theta}}^{LGD}(Tmeters)$ obtained via linear gradient desent versus Tmeters (see example figure 3),
<img src="day01/assets/ex01_price_vs_age_part1.png" />

<img src="day01/assets/ex01_price_vs_thrust_part1.png" />

<img src="day01/assets/ex01_price_vs_Tmeters_part1.png" />


* Plot of rmse with respect to the different features also (figures 4, 5 and 6).
Notice that in the graphs we plot $\sqrt{1/M(\widehat{y^{(i)}} - y^{(i)})^2}$, so it is not the rmse that we plot precisely, but the term in the sum.
**Hint:**
In regard with what I just say, you should consider to add a method maybe named **rmse_components**, If you do not know what I mean maybe your neighbours know ...
<img src="day01/assets/ex01_std_deviation_vs_age.png" />

<img src="day01/assets/ex01_std_deviation_vs_thrust.png" />

<img src="day01/assets/ex01_std_deviation_vs_Tmeters.png" />

Are the fits with a single variable are precised ? Why ? (What did I say a the beginning ?)
What the purpose to represent the "rmse" in function of a feature ?


## Part Two: Multilinear Regression (A New Hope)
Now, it is time for your first multilenear regression !

As you might expected, the formula of the hyphothesis change a little and is given by:
<br>

$$
h(X)= {X} {\theta}
  =\begin{bmatrix} x_0^{(1)} & \cdots & x_N^{(1)}\\ \vdots & \ddots & \vdots \\ x_0^{(m)} & \cdots & x_N^{(m)}  \end{bmatrix} \cdot \begin{bmatrix} \theta_0 \\ \vdots \\ \theta_N\end{bmatrix}
  = \sum{i=1}{N}\theta_ix_i
$$

where ${X}$ is the training dataset matrix, ${\theta}$ the parameter's vector, m is the number of training samples and N the number of features.

But It should not change the methods you coded, hopefully !

For this part, you are expected to:
* Calculate the RMSE and compare it with the ones calculated in the previous part.

**Examples**
```python
>>>import pandas as pd
>>>import numpy as np
>>>form mylinearregression import MyLinearRegression as MyLR
>>>
>>>data = pd.read_csv("spacecraft_data.csv")
>>>[...]
>>>my_lreg = MyLR([1.0, 1.0, 1.0, 1.0])
>>>my_lreg.fit(X,Y)
>>>RMSE = myLR.score(X,Y))
>>>print(RMSE)
27.5049...
```

* Plot the output and predicted output on the same graph in function of the age, thrust power and distance (see figures 3a, 3b and 3c).

<img src="day01/assets/Figure_1a_price_vs_theta.png" />

<img src="day01/assets/Figure_1b_price_vs_theta.png" />

<img src="day01/assets/Figure_1c_price_vs_theta.png" />


## Questions:

Be sure to understand the underlying concept and be able to answer to those questions evaluators may ask:
* What is the learning rate ?
* What allows the linear gradient descent ?
* What information standard deviation gives you ?

