# Exercise 11 - Regularized Gradient

|                         |                    |
| -----------------------:| ------------------ |
|   Turnin directory :    |  ex11              |
|   Files to turn in :    |  vec_reg_grad.py   |
|   Forbidden function :  |  *.sum()           |
|   Remarks :             |  n/a               |

You must implement the following formula as a function:
$$ \nabla(J)_0 = \frac{1}{m} X^T(X\theta - y) $$
$$ \nabla(J)_j = \frac{1}{m} X^T(X\theta - y) + \lambda \theta_j \text{ for j = 1, ..., n}$$

where  
- \nabla(J) is a vector of size n   
- x is a matrix of size m * n (i.e. a matrix containing m vectors of size n)  
- y is a vector of size m  
- \theta is a vector of size n   
- \nabla(J)_j is the jth element of \nabla(J)
- \lambda is a constant

Create a function called `vec_reg_gradient` which takes four arguments : 
  - an array which correspond to the matrix X in the previous formula,
  - an array which correspond to the vector y in the previous formula,
  - an array which correspond to the vector $\theta$,
  - a double corresponding to $\alpha$
  
Your function must return a vector containg the result of the formula for all j, using a vectorized implementation.

hint: there is a smart way to compute the values for the whole $\nabla(J)$ vectors in only one line of code !

```python
>>> X = np.arange(21).reshape((7,3))
>>> X
array([[ 0,  1,  2],
       [ 3,  4,  5],
       [ 6,  7,  8],
       [ 9, 10, 11],
       [12, 13, 14],
       [15, 16, 17],
       [18, 19, 20]])
>>> Y = [2, 14, -13, 5, 12, 4, -19]
>>> th = np.ones(3) * 0.5
>>> vec_reg_grad(X, Y, th, 0.1)
array([207.42857143, 221.72142857, 236.00714286])
>>> vec_reg_grad(X, Y, th * 2, 0.05)
array([396.42857143, 425.72142857, 455.00714286])
```
